{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79f3a5c-3451-41e7-9c1f-55d5d1c7de8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'dates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 227\u001b[0m\n\u001b[1;32m    224\u001b[0m     convert2netcdf(date, dateaddmonth, up\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m, pressure, fname, [x\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m station])\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 196\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m--> 196\u001b[0m     up1, fds1, pressure1, altitude1, station, un \u001b[38;5;241m=\u001b[39m \u001b[43mread_qbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     tnmoth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(up1)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    198\u001b[0m     up \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m15\u001b[39m, tnmoth]) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mread_qbo\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         date\u001b[38;5;241m.\u001b[39mappend(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 75\u001b[0m fds \u001b[38;5;241m=\u001b[39m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[38;5;241m.\u001b[39mdate2num(date)\n\u001b[1;32m     76\u001b[0m un \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m([data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn70\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn50\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn40\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn30\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn20\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn15\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn10\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m     78\u001b[0m pressure \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n",
      "File \u001b[0;32m~/.Venv/Edge/lib/python3.11/site-packages/matplotlib/_api/__init__.py:217\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'dates'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "'''\n",
    "Read QBO data from the following file: http://www.geo.fu-berlin.de/met/ag/strat/produkte/qbo/qbo.dat\n",
    "'''\n",
    "\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cftime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def read_singapore(nmonth, nyear):\n",
    "    headerlines = []\n",
    "    ye = []\n",
    "    dats = []\n",
    "    count = 0\n",
    "    date = []\n",
    "    with open('../QBO/qbo_data/singapore.dat') as file:\n",
    "        for i in range(3):\n",
    "            headerlines.append(file.readline().strip())\n",
    "        for year in range(1987, nyear):\n",
    "            data = np.zeros([nmonth, 15]) * np.nan if year == nyear else np.zeros([12, 15]) * np.nan\n",
    "            ye.append(file.readline().strip())\n",
    "            file.readline()\n",
    "            if year < 1997:\n",
    "                data = np.zeros([12, 15]) * np.nan\n",
    "                for i in range(14):\n",
    "                    cols = file.readline().strip().split()\n",
    "                    for j in range(1, 13):\n",
    "                        if i == 1:\n",
    "                            date.append(datetime.datetime(year, j, 1))\n",
    "                        data[j - 1, i] = float(cols[j])\n",
    "            else:\n",
    "                for i in range(15):\n",
    "                    cols = file.readline().strip().split()\n",
    "                    for j in range(1, 13):\n",
    "                        if j < nmonth + 1 or year < nyear:\n",
    "                            if i == 1:\n",
    "                                date.append(datetime.datetime(year, j, 1))\n",
    "                            data[j - 1, i] = float(cols[j])\n",
    "            dats.extend([list(i) for i in data])\n",
    "            file.readline()\n",
    "            count += 1\n",
    "    pressure = [100, 90, 80, 70, 60, 50, 45, 40, 35, 30, 25, 20, 15, 12, 10]\n",
    "    altitude = -7 * np.log(np.array(pressure) / 1013.15)\n",
    "    fds = list(mpl.dates.date2num(date))\n",
    "    fds = np.array(fds)\n",
    "    return np.array(dats).T[::-1], fds, pressure, altitude\n",
    "\n",
    "def read_qbo():\n",
    "    with open('../QBO/qbo_data/qbo.dat', 'r') as file:\n",
    "        header_lines = [file.readline().strip() for _ in range(9)]\n",
    "    \n",
    "    data = np.genfromtxt(\n",
    "        '../QBO/qbo_data/qbo.dat',\n",
    "        skip_header=9,\n",
    "        dtype=['S6', 'S4', 'i4', 'i1', 'i4', 'i1', 'i4', 'i1', 'i4', 'i1', 'i4', 'i1', 'i4', 'i1', 'i4', 'i1'],\n",
    "        names=['station', 'date', 'p70', 'n70', 'p50', 'n50', 'p40', 'n40', 'p30', 'n30', 'p20', 'n20', 'p15', 'n15', 'p10', 'n10'],\n",
    "        delimiter=[6, 4, 6, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2],\n",
    "        filling_values=-999999, missing_values=' '\n",
    "    )\n",
    "    \n",
    "    station = np.char.decode(data['station'], 'utf-8').astype(str)\n",
    "    station = np.char.strip(station)\n",
    "    \n",
    "    date = []\n",
    "    for i in range(len(data)):\n",
    "        if int(data['date'][i]) > 5000:\n",
    "            date.append(datetime.datetime.strptime('19' + (data['date'][i]).decode('UTF-8'), '%Y%m'))\n",
    "        else:\n",
    "            date.append(datetime.datetime.strptime('20' + (data['date'][i]).decode('UTF-8'), '%Y%m'))\n",
    "    \n",
    "    fds = mpl.dates.date2num(date)\n",
    "    un = np.array(list([data['n70'], data['n50'], data['n40'], data['n30'], data['n20'], data['n15'], data['n10']]))\n",
    "    \n",
    "    pressure = [70, 50, 40, 30, 20, 15, 10]\n",
    "    altitude = -7 * np.log(np.array(pressure) / 1013.15)\n",
    "    return un, fds, pressure, altitude, station, un\n",
    "\n",
    "def convert2netcdf(date, dateaddmonth, u, pressure, fname, station):\n",
    "    station_id = []\n",
    "    station_name = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "\n",
    "    for s_code in station:\n",
    "        if s_code == '91700':\n",
    "            station_id.append(s_code)\n",
    "            station_name.append('CANTON ISLAND')\n",
    "            latitude.append(-(2 + 46 / 60))       #   2°46' S\n",
    "            longitude.append(-(171 + 43 / 60))    # 171°43' W\n",
    "        elif s_code in ['48968', '48698', '48964', '48694', '08694']:\n",
    "            if s_code.endswith('4'):\n",
    "                station_id.append('48694')\n",
    "            elif s_code.endswith('8'):\n",
    "                station_id.append('48698')\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported station code: {s_code}\")\n",
    "            station_name.append('SINGAPORE')\n",
    "            latitude.append(1 + 22 / 60)          #   1°22' N\n",
    "            longitude.append(103 + 55 / 60)       # 103°55' E\n",
    "        elif s_code == '43599':\n",
    "            station_id.append(s_code)\n",
    "            station_name.append('GAN/MALEDIVES')\n",
    "            latitude.append(-(41 / 60))           #   0°41' S\n",
    "            longitude.append(73 + 9 / 60)         #  73°09' E\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported station code: {s_code}\")\n",
    "\n",
    "    ds = xr.Dataset({\n",
    "        'u': (['time', 'pressure'], u),\n",
    "        'station_id': (['time'], station_id),\n",
    "        'station_name': (['time'], station_name),\n",
    "        'latitude': (['time'], latitude),\n",
    "        'longitude': (['time'], longitude),\n",
    "    }, coords={\n",
    "        'pressure': pressure,\n",
    "        'time': date,\n",
    "    })\n",
    "    \n",
    "    ds['u_qc'] = xr.DataArray(\n",
    "        np.where((ds['u'] >= -200) & (ds['u'] <= 200), 0, 1),\n",
    "        coords=ds['u'].coords, dims=ds['u'].dims\n",
    "    ).astype(np.int32)\n",
    "\n",
    "    time_bounds = xr.DataArray(\n",
    "        np.array([date, dateaddmonth]).T,\n",
    "        dims=['time', 'bounds'],\n",
    "        attrs={'units': 'days since 1950-01-01 00:00:00'}\n",
    "    )\n",
    "    \n",
    "    ds['time_bounds'] = time_bounds\n",
    "    time_bounds.attrs = {'long_name': 'Time Bounds', \n",
    "                         'standard_name': 'time_bounds',\n",
    "                         'units': 'days since 1950-01-01 00:00:00'}\n",
    "    \n",
    "    ds.coords['time_bounds'] = time_bounds\n",
    "    \n",
    "    ds['time'].attrs = {'standard_name': 'time', \n",
    "                        'long_name': 'Time',\n",
    "                        'units': 'days since 1950-01-01 00:00:00', \n",
    "                        'cell_methods':  'time: mean over calendar_month',\n",
    "                        'bounds': 'time_bounds'}  \n",
    "    \n",
    "    ds['pressure'].attrs = {'standard_name': 'air_pressure', \n",
    "                            'long_name': 'Atmospheric Pressure',\n",
    "                            'units': 'hPa',\n",
    "                            'axis': 'Z'}\n",
    "    \n",
    "    ds['u'].attrs = {'standard_name': 'eastward_wind', \n",
    "                     'long_name': 'Eastward Wind',\n",
    "                     'units': 'm/s',\n",
    "                     'cell_methods': 'time: mean over calendar_month',\n",
    "                     '_FillValue': np.nan,\n",
    "                     'u_qc': 0}\n",
    "\n",
    "    ds['latitude'].attrs = {'long_name': 'Latitude', 'standard_name': 'latitude', 'units': 'degrees_north'}\n",
    "    ds['longitude'].attrs = {'long_name': 'Longitude', 'standard_name': 'longitude', 'units': 'degrees_east'}\n",
    "\n",
    "    ds['u_qc'].attrs = {'long_name': 'Quality flag for eastward wind', \n",
    "                        'flag_values': np.array([0, 1], dtype=np.int32),\n",
    "                        'flag_meanings': 'interpolated missing'}\n",
    "\n",
    "    ds.attrs = {'Conventions': 'CF-1.6, CF-1.7, CF-1.8, IOOS-1.2, ACDD-1.3', \n",
    "                'title': 'Monthly mean zonal winds', \n",
    "                'summary': 'Collection of tropical winds originally from the FU Berlin to represent QBO data',\n",
    "                'history': 'Created by Tobias Kerzenmacher using FUB processing chain', \n",
    "                'source': 'FUB and Singapore radiosondes',\n",
    "                'comment': 'Monthly mean zonal winds at the levels 100, 90, 80, 70, 60, 50, 45, 40, 35, 30, 25, 20, 15, 12, and 10-hPa from Radiosonde data of of the three radiosonde stations Canton Island (closed 1967), Gan/Maledive Islands (closed 1975), and Singapore near the equator from 1953 to the present.',\n",
    "                'institution': 'Karlsruhe Institute of Technology (KIT), Institute of Meteorology and Climate Research (IMK), Germany',\n",
    "                'institution_id': 'ROR:04t3en479',\n",
    "                'license': 'CC-BY 4.0',\n",
    "                'keywords': 'QBO, radiosonde, zonal wind',\n",
    "                'frequency': '1M',\n",
    "                'creator_url': 'https://orcid.org/0000-0001-8413-0539',\n",
    "                'creator_email': 'kerzenmacher@kit.edu',\n",
    "                'contact': 'kerzenmacher@kit.edu',\n",
    "                'creation_date': datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'),\n",
    "                'further_info_url': 'https://www.atmohub.kit.edu/english/807.php',\n",
    "                'references': 'Barbara Naujokat (1986) doi: https://doi.org/10.1175/1520-0469(1986)043<1873:AUOTOQ>2.0.CO;2  Christian Marquardt (1998) Die tropische QBO und dynamische Prozesse in der Stratosphäre. PhD Thesis, Met. Abh. FU-Berlin, Serie A, Band 9/Heft 4, Verlag Dietrich Reimer Berlin, 260 S.',\n",
    "                'standard_name_vocabulary': 'CF Standard Name Table, Version 83',\n",
    "                'crs': 'wgs84'\n",
    "               }\n",
    "\n",
    "    ds['pressure'] = ds['pressure'].astype(np.float64)\n",
    "    ds['time'] = ds['time'].astype(np.float64)\n",
    "    ds['u'] = ds['u'].astype(np.float64)\n",
    "    ds['time_bounds'] = ds['time_bounds'].astype(np.float64)\n",
    "\n",
    "    ds.to_netcdf(fname)\n",
    "    return ds\n",
    "\n",
    "def main():\n",
    "    up1, fds1, pressure1, altitude1, station, un = read_qbo()\n",
    "    tnmoth = np.shape(up1)[1]\n",
    "    up = np.zeros([15, tnmoth]) * np.nan\n",
    "    nmonth = np.shape(up1)[1] % 12\n",
    "    nyear = mpl.dates.num2date(fds1[-1]).year\n",
    "    up2, fds2, pressure, altitude = read_singapore(nmonth, nyear)\n",
    "    fds = fds1\n",
    "    fds[-fds2.size:] = fds2\n",
    "    fds = np.array(fds)\n",
    "\n",
    "    up1 = up1 * 1.0\n",
    "    up1[up1 < -10000] = np.nan\n",
    "    up[3, :] = up1[0, :]\n",
    "    up[5, :] = up1[1, :]\n",
    "    up[7, :] = up1[2, :]\n",
    "    up[9, :] = up1[3, :]\n",
    "    up[11, :] = up1[4, :]\n",
    "    up[12, :] = up1[5, :]\n",
    "    up[14, :] = up1[6, :]\n",
    "    up[-up2.shape[0]:, -up2.shape[1]:] = up2\n",
    "\n",
    "    time = mpl.dates.num2date(fds)\n",
    "    offset = relativedelta(months=1)\n",
    "    timeaddmonth = [pd.to_datetime(t) + offset for t in time]\n",
    "    date = cftime.date2num(time, 'days since 1950-01-01 00:00:00', 'standard')\n",
    "    dateaddmonth = cftime.date2num(timeaddmonth, 'days since 1950-01-01 00:00:00', 'standard')\n",
    "\n",
    "    fname = 'eastward_wind_{}{:02d}.nc'.format(time[0].year, time[0].month)\n",
    "    convert2netcdf(date, dateaddmonth, up.T * 0.1, pressure, fname, [x.decode(\"utf-8\").strip() for x in station])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292fc6b5-f64f-42db-9f2c-aaf6ac17b473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
